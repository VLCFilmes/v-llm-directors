# V-LLM Directors Configuration

# OpenAI API
OPENAI_API_KEY=sk-proj-your_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Modelos disponíveis:
# - gpt-3.5-turbo (barato, rápido, ~$0.001/1K tokens)
# - gpt-4o-mini (intermediário, ~$0.15/1M input, ~$0.6/1M output)
# - gpt-4o (mais capaz, ~$2.5/1M input, ~$10/1M output)
# - gpt-4-turbo (alta performance, ~$10/1M input, ~$30/1M output)

# Server
HOST=0.0.0.0
PORT=5025
DEBUG=false

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=60
MAX_TOKENS_PER_REQUEST=4000

# Timeouts
LLM_TIMEOUT_SECONDS=60
REQUEST_TIMEOUT_SECONDS=120

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Integration URLs
V_SERVICES_URL=http://v-services:5000
V_API_URL=http://v-api:8000

# Cache (Optional)
ENABLE_CACHE=true
CACHE_TTL_SECONDS=3600
